{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path \n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rvissche/Nextcloud/What-If/what-if-data-donation/what-if-data-donation/structure_donations/Processed_structure_donations/TikTok/Input_test\n"
     ]
    }
   ],
   "source": [
    "main_path = \"/home/rvissche/Nextcloud/What-If/what-if-data-donation/what-if-data-donation/structure_donations/Processed_structure_donations/\"\n",
    "input_directory = Path(f'{main_path}TikTok/Input_test')  \n",
    "print(input_directory)\n",
    "max_columns = 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(max_columns):\n",
    "        col_path = [f\"col_path_{i}\" for i in range(max_columns)]\n",
    "        col_path_values = [f\"col_path_{i}_values\" for i in range(1, max_columns)]\n",
    "        col_path_list = [f\"col_path_{i}_lIST\" for i in range(1, max_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['col_path_1_values', 'col_path_2_values', 'col_path_3_values', 'col_path_4_values', 'col_path_5_values', 'col_path_6_values']\n"
     ]
    }
   ],
   "source": [
    "print(col_path_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_data(data):\n",
    "    \n",
    "\n",
    "    with open(data, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['col_path_0_values'] = data\n",
    "    df['col_path_0'] = ''\n",
    "    \n",
    "    df.reset_index(inplace = True)\n",
    "    df = df.drop('index', axis = 1)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    for i in range(1,max_columns):   \n",
    "        df[f'col_path_{i}'] = ''\n",
    "        df[f'col_path_{i}_values'] = ''\n",
    "        df[f'col_path_{i}_LIST'] = ''\n",
    "\n",
    "\n",
    "    \n",
    "    return(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flatten_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_json(df):\n",
    "    \n",
    "\n",
    "    for i in range(max_columns):\n",
    "        for ix, row in df.iterrows():\n",
    "            value= row[f'col_path_{i}_values']\n",
    "            \n",
    "            if isinstance(value, dict):\n",
    "                \n",
    "                for k, v in value.items():\n",
    "                    if isinstance(v, list):\n",
    "                        v = v[0]\n",
    "                        list_holder = 'LIST'\n",
    "                    \n",
    "                    \n",
    "                    else:\n",
    "                        list_holder = 'NO LIST'\n",
    "                    \n",
    "\n",
    "                    new_row = row.copy()\n",
    "                    new_row[ f'col_path_{i+1}_values'] = v\n",
    "                    new_row[ f'col_path_{i}'] = k\n",
    "                    new_row[f'col_path_{i+1}_LIST'] = list_holder\n",
    "                    df.loc[len(df)] = new_row\n",
    "                        \n",
    "\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "    df_red = df.drop(columns=[col for col in df.columns if col.endswith(\"_LIST\")])\n",
    "    \n",
    "    df_red['last_valid_index'] = df_red.apply(pd.Series.last_valid_index, axis=1)\n",
    "    df_red = df_red.drop(columns=[col for col in df.columns if col.endswith(\"values\")])\n",
    "\n",
    "\n",
    "    df = pd.merge(df, df_red, on = col_path, how='left')\n",
    "    \n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process_col_path()\n",
    "The 'process_col_path()' function checks whether the value in a row of for one of the column paths is actually a datatype and stores this value in a column data_type and replaces the original value with NA. The data types are the lowest level values in the JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data types\n",
    "data_types = ['string', 'array', 'number', 'boolean', 'object', 'str', 'int', 'float', 'bool', 'dict', 'list']\n",
    "\n",
    "\n",
    "\n",
    "# Define the function 'process_col_path()'\n",
    "def process_col_path(df, col_path_values, data_types):\n",
    "    df['data_type'] = ''\n",
    "\n",
    "    \"\"\"\n",
    "    row: Rows in the dataframe\n",
    "    columns: List of column names of column path columns \n",
    "    data_types: List of the values that are data types\n",
    "    \"\"\"\n",
    "    \n",
    "    for ix, row in df.iterrows():\n",
    "        for col in col_path_values:\n",
    "            \n",
    "\n",
    "            #If the value stored in the column is found in the list 'data_types', \n",
    "            if row[col] in data_types:\n",
    "                # this value is placed in the column 'data_type'\n",
    "                value = row[col]\n",
    "                \n",
    "                df.at[ix, 'data_type'] = value\n",
    "            else:\n",
    "                continue\n",
    "               \n",
    "    \n",
    "                \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove_intermediate_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_intermediate_rows(df):\n",
    "    drop_index = []\n",
    "    for ix, row in df.iterrows():\n",
    "            last_value = row[f\"{row['last_valid_index']}\"]\n",
    "           \n",
    "        \n",
    "            if isinstance(last_value, str):\n",
    "                    if last_value in (data_types):\n",
    "                            col =  row['last_valid_index']\n",
    "                            col_level = re.findall(r'\\d+', col)\n",
    "                            col_level = col_level[0]\n",
    "                           \n",
    "                            \n",
    "                            df.at[ix, f\"col_path_{col_level}_LIST\"] = np.nan\n",
    "\n",
    "                            \n",
    "            else:\n",
    "                   drop_index.append(ix)\n",
    "   \n",
    "    df = df.drop(drop_index)\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_path(df, max_columns):\n",
    "    \n",
    "    df['path']= ''\n",
    "    \n",
    "    for ix, row in df.iterrows():\n",
    "        path = []\n",
    "    \n",
    "        for col in [f\"col_path_{i}\" for i in range(max_columns)]:\n",
    "            val = row[col]\n",
    "        \n",
    "            if pd.notna(val):\n",
    "\n",
    "                path.append(str(val).strip())\n",
    "\n",
    "      \n",
    "        \n",
    "        df.at[ix, 'path'] = path\n",
    "       \n",
    "    \n",
    "        \n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_path(df):\n",
    "    \n",
    "    df['list_path'] = ''\n",
    "    df['subfield_path'] = ''\n",
    "    df['column_name'] = ''\n",
    "    df['var_type'] = ''\n",
    "    \n",
    "\n",
    "\n",
    "    for ix, row in df.iterrows():\n",
    "        \n",
    "        path = row['path'] \n",
    "        \n",
    "        \n",
    "        for i in range(1, len(path)):\n",
    "           \n",
    "            if row[f\"col_path_{i}_LIST\"] == 'LIST':\n",
    "                var_type = 'list'\n",
    "                list_path = json.dumps(path[:-1])\n",
    "                subfield_path = path[-1]\n",
    "                column_name = subfield_path\n",
    "                subfield_path = json.dumps(subfield_path)\n",
    "\n",
    "            elif row[f\"col_path_{i}_LIST\"] == \"NO LIST\":\n",
    "                var_type = 'static'\n",
    "                list_path = np.nan\n",
    "                subfield_path = json.dumps(path)\n",
    "                column_name = path[-1]\n",
    "             \n",
    "            elif row[f\"col_path_{i}_LIST\"] == 'nan':\n",
    "                var_type = 'skip'\n",
    "                list_path = np.nan\n",
    "                subfield_path = json.dumps(path)\n",
    "                column_name = path[-1]\n",
    "               \n",
    "            else:\n",
    "                var_type = 'skip'\n",
    "                list_path = np.nan\n",
    "                subfield_path = json.dumps(path)\n",
    "                column_name = path[-1]\n",
    "\n",
    "\n",
    "           \n",
    "    \n",
    "        df.at[ix, 'list_path'] = list_path\n",
    "        df.at[ix, 'subfield_path'] = subfield_path\n",
    "        df.at[ix, 'column_name'] = column_name\n",
    "        df.at[ix, 'var_type'] = var_type\n",
    "\n",
    "    \n",
    "      \n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean_and_store()\n",
    "This function orders the columns in the DataFrame, resets the index, fills the NA and saves the DataFrame as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_store(df, file_name):\n",
    "\n",
    "    \"\"\"\n",
    "    df: The dataframe that will be cleaned and stored\n",
    "    file_name: The filename of data structure that is being processed\n",
    "    \"\"\"\n",
    "\n",
    "  \n",
    "   \n",
    "    df=  df[df['col_path_0'] != 'Direct Message']\n",
    "    \n",
    "    \n",
    "  \n",
    "    df = df[['column_name', 'path', 'list_path', 'subfield_path', 'var_type', 'data_type']]\n",
    "    # Save the DataFrame \n",
    "    df.to_csv(f\"{main_path}TikTok/Output/Output_\" + file_name + '.csv', index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### structure_donations()\n",
    "The structure_donations() function executes all functions above and results in a saved DataFrame for each data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_donations(data, col_path, max_columns):\n",
    "     # Store the path to the data structure\n",
    "    data = Path(data)  \n",
    "    \n",
    "    # Save teh file name of the data structure\n",
    "    file_name = Path(data).stem \n",
    "\n",
    "    df = loading_data(data)\n",
    "    print('FINISH: loading_data()')\n",
    "    df = flatten_json(df)\n",
    "    print('FINISH: flatten_json()')\n",
    "    df = process_col_path(df, col_path_values, data_types)\n",
    "    print('FINISH: process_col_path()')\n",
    "    df = remove_intermediate_rows(df)\n",
    "    print('FINISH: remove_intermediate_rows()')\n",
    "    df = extract_path(df, max_columns)\n",
    "    print('FINISH: extract_path()')\n",
    "    df = list_path(df)\n",
    "    print('FINISH: list_path()')\n",
    "    df = clean_and_store(df, file_name)\n",
    "    print('FINISH: clean_and_store()')\n",
    "\n",
    "    return(df)\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute 'structure_donations()': Transform data structures from JSON format to tabular format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HJ_tiktol_json_strcure.json\n",
      "FINISH: loading_data()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31697/2132457031.py:31: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISH: flatten_json()\n",
      "FINISH: process_col_path()\n",
      "FINISH: remove_intermediate_rows()\n",
      "FINISH: extract_path()\n",
      "FINISH: list_path()\n",
      "FINISH: clean_and_store()\n",
      "TT_structure_tiktok_takeout_ro.json\n",
      "FINISH: loading_data()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31697/2132457031.py:31: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
      "/tmp/ipykernel_31697/2132457031.py:31: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISH: flatten_json()\n",
      "FINISH: process_col_path()\n",
      "FINISH: remove_intermediate_rows()\n",
      "FINISH: extract_path()\n",
      "FINISH: list_path()\n",
      "FINISH: clean_and_store()\n",
      "extra_tiktok_json_structure.json\n",
      "FINISH: loading_data()\n",
      "FINISH: flatten_json()\n",
      "FINISH: process_col_path()\n",
      "FINISH: remove_intermediate_rows()\n",
      "FINISH: extract_path()\n",
      "FINISH: list_path()\n",
      "FINISH: clean_and_store()\n",
      "TT_structure_tiktok_takeout_es.json\n",
      "FINISH: loading_data()\n",
      "FINISH: flatten_json()\n",
      "FINISH: process_col_path()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31697/2132457031.py:31: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISH: remove_intermediate_rows()\n",
      "FINISH: extract_path()\n",
      "FINISH: list_path()\n",
      "FINISH: clean_and_store()\n",
      "TT_structure_user_data_tiktok.json\n",
      "FINISH: loading_data()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31697/2132457031.py:31: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISH: flatten_json()\n",
      "FINISH: process_col_path()\n",
      "FINISH: remove_intermediate_rows()\n",
      "FINISH: extract_path()\n",
      "FINISH: list_path()\n",
      "FINISH: clean_and_store()\n",
      "TT_structure_tiktok_takeout_dutch.json\n",
      "FINISH: loading_data()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31697/2132457031.py:31: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
      "/tmp/ipykernel_31697/2132457031.py:31: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISH: flatten_json()\n",
      "FINISH: process_col_path()\n",
      "FINISH: remove_intermediate_rows()\n",
      "FINISH: extract_path()\n",
      "FINISH: list_path()\n",
      "FINISH: clean_and_store()\n",
      "TT_json_structure_MvdV.json\n",
      "FINISH: loading_data()\n",
      "FINISH: flatten_json()\n",
      "FINISH: process_col_path()\n",
      "FINISH: remove_intermediate_rows()\n",
      "FINISH: extract_path()\n",
      "FINISH: list_path()\n",
      "FINISH: clean_and_store()\n",
      "tiktok_takeout_dutch_structure.json\n",
      "FINISH: loading_data()\n",
      "FINISH: flatten_json()\n",
      "FINISH: process_col_path()\n",
      "FINISH: remove_intermediate_rows()\n",
      "FINISH: extract_path()\n",
      "FINISH: list_path()\n",
      "FINISH: clean_and_store()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31697/2132457031.py:31: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True)\n"
     ]
    }
   ],
   "source": [
    "# Execute the 'structure_donations()' function for each file (data structure) in the input directory\n",
    "for file in input_directory.iterdir():  \n",
    "    if file.is_file():  \n",
    "        print(file.name)\n",
    "        structure_donations(file, col_path, max_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all data structures into one schema_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>path</th>\n",
       "      <th>list_path</th>\n",
       "      <th>subfield_path</th>\n",
       "      <th>var_type</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>App</td>\n",
       "      <td>['Favorite Videos', 'App']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Favorite Videos\", \"App\"]</td>\n",
       "      <td>static</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>App</td>\n",
       "      <td>['Follower List', 'App']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Follower List\", \"App\"]</td>\n",
       "      <td>static</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IsFastLane</td>\n",
       "      <td>['Follower List', 'IsFastLane']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Follower List\", \"IsFastLane\"]</td>\n",
       "      <td>static</td>\n",
       "      <td>boolean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>App</td>\n",
       "      <td>['Following List', 'App']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Following List\", \"App\"]</td>\n",
       "      <td>static</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IsFastLane</td>\n",
       "      <td>['Following List', 'IsFastLane']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Following List\", \"IsFastLane\"]</td>\n",
       "      <td>static</td>\n",
       "      <td>boolean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>AIGeneratedContent</td>\n",
       "      <td>['RecentlyDeletedPosts', 'PostList', 'AIGenera...</td>\n",
       "      <td>[\"RecentlyDeletedPosts\", \"PostList\"]</td>\n",
       "      <td>\"AIGeneratedContent\"</td>\n",
       "      <td>list</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>Sound</td>\n",
       "      <td>['RecentlyDeletedPosts', 'PostList', 'Sound']</td>\n",
       "      <td>[\"RecentlyDeletedPosts\", \"PostList\"]</td>\n",
       "      <td>\"Sound\"</td>\n",
       "      <td>list</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>Location</td>\n",
       "      <td>['RecentlyDeletedPosts', 'PostList', 'Location']</td>\n",
       "      <td>[\"RecentlyDeletedPosts\", \"PostList\"]</td>\n",
       "      <td>\"Location\"</td>\n",
       "      <td>list</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>Title</td>\n",
       "      <td>['RecentlyDeletedPosts', 'PostList', 'Title']</td>\n",
       "      <td>[\"RecentlyDeletedPosts\", \"PostList\"]</td>\n",
       "      <td>\"Title\"</td>\n",
       "      <td>list</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>AddYoursText</td>\n",
       "      <td>['RecentlyDeletedPosts', 'PostList', 'AddYours...</td>\n",
       "      <td>[\"RecentlyDeletedPosts\", \"PostList\"]</td>\n",
       "      <td>\"AddYoursText\"</td>\n",
       "      <td>list</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            column_name                                               path  \\\n",
       "0                   App                         ['Favorite Videos', 'App']   \n",
       "1                   App                           ['Follower List', 'App']   \n",
       "2            IsFastLane                    ['Follower List', 'IsFastLane']   \n",
       "3                   App                          ['Following List', 'App']   \n",
       "4            IsFastLane                   ['Following List', 'IsFastLane']   \n",
       "..                  ...                                                ...   \n",
       "909  AIGeneratedContent  ['RecentlyDeletedPosts', 'PostList', 'AIGenera...   \n",
       "910               Sound      ['RecentlyDeletedPosts', 'PostList', 'Sound']   \n",
       "911            Location   ['RecentlyDeletedPosts', 'PostList', 'Location']   \n",
       "912               Title      ['RecentlyDeletedPosts', 'PostList', 'Title']   \n",
       "913        AddYoursText  ['RecentlyDeletedPosts', 'PostList', 'AddYours...   \n",
       "\n",
       "                                list_path                     subfield_path  \\\n",
       "0                                     NaN        [\"Favorite Videos\", \"App\"]   \n",
       "1                                     NaN          [\"Follower List\", \"App\"]   \n",
       "2                                     NaN   [\"Follower List\", \"IsFastLane\"]   \n",
       "3                                     NaN         [\"Following List\", \"App\"]   \n",
       "4                                     NaN  [\"Following List\", \"IsFastLane\"]   \n",
       "..                                    ...                               ...   \n",
       "909  [\"RecentlyDeletedPosts\", \"PostList\"]              \"AIGeneratedContent\"   \n",
       "910  [\"RecentlyDeletedPosts\", \"PostList\"]                           \"Sound\"   \n",
       "911  [\"RecentlyDeletedPosts\", \"PostList\"]                        \"Location\"   \n",
       "912  [\"RecentlyDeletedPosts\", \"PostList\"]                           \"Title\"   \n",
       "913  [\"RecentlyDeletedPosts\", \"PostList\"]                    \"AddYoursText\"   \n",
       "\n",
       "    var_type data_type  \n",
       "0     static    number  \n",
       "1     static    number  \n",
       "2     static   boolean  \n",
       "3     static    number  \n",
       "4     static   boolean  \n",
       "..       ...       ...  \n",
       "909     list    string  \n",
       "910     list    string  \n",
       "911     list    string  \n",
       "912     list    string  \n",
       "913     list    string  \n",
       "\n",
       "[311 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Path to the folder containing CSV files\n",
    "output_path = f\"{main_path}TikTok/Output\"\n",
    "\n",
    "# Get a list of all CSV files in the folder\n",
    "csv_files = list(Path(output_path).glob(\"*.csv\"))\n",
    "\n",
    "# Load all CSVs into a list of DataFrames\n",
    "dfs = [pd.read_csv(file) for file in csv_files]\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "merged_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "# Drop rows that are completely identical across all columns\n",
    "merged_df = merged_df.drop_duplicates()\n",
    "display(merged_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Id creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_df = merged_df[['path', 'column_name']]\n",
    "id_df = id_df.drop_duplicates()\n",
    "id_df[ 'id'] = ''\n",
    "\n",
    "\n",
    "\n",
    "for n in range(1, max_columns):\n",
    "    duplicates = id_df[id_df.duplicated(subset='id', keep=False)]\n",
    "\n",
    "    for i, row in duplicates.iterrows():\n",
    "        path = row['path']\n",
    "        path =  ast.literal_eval(path)\n",
    "        path_zero = path[0]\n",
    "        path_rest = path[-n:]  # Varies each loop to attempt uniqueness\n",
    "        id_list = [path_zero] + path_rest\n",
    "        new_id = ':'.join(id_list)\n",
    "\n",
    "        id_df.at[i, 'id'] = new_id  # Properly update the DataFrame\n",
    "\n",
    "\n",
    "\n",
    "merged_df = pd.merge(merged_df, id_df, on = ['path', 'column_name'], how = 'left')\n",
    "\n",
    "col = merged_df.pop('id') \n",
    "merged_df.insert(0, 'id', col) \n",
    "#merged_df['id']= merged_df['id'].fillna(merged_df['variable'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ID duplicate flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31697/29815283.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dup['duplicate_flag'] = 'Yes'\n"
     ]
    }
   ],
   "source": [
    "merged_df = merged_df.drop_duplicates()\n",
    "dup = merged_df[merged_df.duplicated('id', keep= False)]\n",
    "dup['duplicate_flag'] = 'Yes'\n",
    "dup = dup[['id', 'duplicate_flag']]\n",
    "merged_df = pd.merge(merged_df, dup, on = 'id', how = 'left')\n",
    "merged_df['duplicate_flag'] = merged_df['duplicate_flag'].fillna(value = 'No')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['json_name'] = ''\n",
    "\n",
    "keep_columns = ['id', 'column_name', \n",
    "                 'path', 'list_path', 'subfield_path', \n",
    "                 'var_type', 'data_type', 'json_name', 'duplicate_flag']\n",
    "\n",
    "\n",
    "merged_df = merged_df[keep_columns ]\n",
    "\n",
    "# Save the final merged DataFrame\n",
    "merged_df.to_csv(f\"{main_path}TikTok/Final/Merged_structures_TT.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-donations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
